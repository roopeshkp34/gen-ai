{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "728a2baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ഹായ്!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 20, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'id': 'chatcmpl-BUSJfOqrNlyKRWKHo1YyRG4wY1Qfn', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9f09ae7a-99e1-4eb6-9523-ac1f635d3c29-0', usage_metadata={'input_tokens': 20, 'output_tokens': 4, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Malayalam\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff2f193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|ഹ|ായ്|!||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ff8431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f0b7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Hindi', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Hindi\", \"text\": \"hi!\"})\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51fd5af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Hindi', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e8a442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "नमस्ते!\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a287e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Malayalam\", \"text\": \"Who are you\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b65848ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'നിങ്ങൾ ആരാണ്?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46f554b",
   "metadata": {},
   "source": [
    "# Lang chain tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80e22eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "# tools\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c423e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools  = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "787e3ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "messages = [HumanMessage(query)]\n",
    "ai_message = model_with_tools.invoke(query)\n",
    "messages.append(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcf8fd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WSxOnUPQr0S0uABDy0ZSUXxy', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_V3F6vVtlVM7OBfV0J7kSdPP2', 'function': {'arguments': '{\"a\": 11, \"b\": 49}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 97, 'total_tokens': 148, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BUTA1AOEe8LqEBPr5tNxcrPtmndLH', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4e8ac4a6-51d7-4aa2-a896-5597d51bd442-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_WSxOnUPQr0S0uABDy0ZSUXxy', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_V3F6vVtlVM7OBfV0J7kSdPP2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 97, 'output_tokens': 51, 'total_tokens': 148, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='36', name='multiply', tool_call_id='call_WSxOnUPQr0S0uABDy0ZSUXxy'),\n",
       " ToolMessage(content='60', name='add', tool_call_id='call_V3F6vVtlVM7OBfV0J7kSdPP2')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_message.tool_calls:\n",
    "    selected_tool = globals()[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70e7f0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The result of \\\\( 3 \\\\times 12 \\\\) is \\\\( 36 \\\\), and the result of \\\\( 11 + 49 \\\\) is \\\\( 60 \\\\).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 163, 'total_tokens': 201, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BUTGeFM4PXpeUnPh5PKJ3tiFCcRzW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--ac500205-0ddf-44be-a15f-465153b17f2c-0', usage_metadata={'input_tokens': 163, 'output_tokens': 38, 'total_tokens': 201, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df8845",
   "metadata": {},
   "source": [
    "# Stream Tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3c0a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fd1374c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[{'name': 'multiply', 'args': '', 'id': 'call_p4l1nmf2bYZa0Xa8pBzMRYAu', 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': '{\"a\"', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': ': 3, ', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': '\"b\": 1', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': '2}', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "[{'name': 'add', 'args': '', 'id': 'call_oMNPlRjo2KaXBG9hmtxvo37n', 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': '{\"a\"', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': ': 11,', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': ' \"b\": ', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': '49}', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "async for chunk in llm_with_tools.astream(query):\n",
    "    print(chunk.tool_call_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b884573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
